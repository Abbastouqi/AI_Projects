# ğŸ¦Ÿ Dengue Outbreak Predictor

A comprehensive machine learning project for predicting dengue fever outbreaks using climate data and advanced anomaly detection techniques.

## ğŸ“‹ Project Overview

This project implements a complete pipeline for dengue outbreak prediction including:

- **Data Collection**: Merge climate data with case reports and store in SQLite database
- **Data Wrangling**: Handle missing values, outliers, and inconsistent date formats
- **Feature Engineering**: Create lag features, rolling averages, and seasonal indicators
- **ML Models**: Train and compare k-NN, Naive Bayes, and Random Forest models
- **Anomaly Detection**: Flag unusual spikes that might indicate outbreaks
- **Dashboard**: Interactive Streamlit app with risk maps and predictions

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- Virtual environment (recommended)

### Installation

1. **Clone and setup environment:**
```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

2. **Run the complete pipeline:**
```bash
python main.py
```

3. **Launch the dashboard:**
```bash
streamlit run src/dashboard.py
```

## ğŸ“ Project Structure

```
Dengue-Outbreak-Predictor/
â”œâ”€â”€ archive (4)/                    # Raw dataset files
â”‚   â”œâ”€â”€ DengAI_Predicting_Disease_Spread_-_Training_Data_Features.csv
â”‚   â”œâ”€â”€ DengAI_Predicting_Disease_Spread_-_Training_Data_Labels.csv
â”‚   â”œâ”€â”€ DengAI_Predicting_Disease_Spread_-_Test_Data_Features.csv
â”‚   â””â”€â”€ DengAI_Predicting_Disease_Spread_-_Submission_Format.csv
â”œâ”€â”€ src/                           # Source code modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_collection.py         # Data loading and database operations
â”‚   â”œâ”€â”€ data_wrangling.py          # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ feature_engineering.py     # Feature creation and transformation
â”‚   â”œâ”€â”€ ml_models.py               # Machine learning models
â”‚   â”œâ”€â”€ anomaly_detection.py       # Outbreak anomaly detection
â”‚   â””â”€â”€ dashboard.py               # Streamlit dashboard
â”œâ”€â”€ main.py                        # Main execution script
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸ¯ Key Results

- **Random Forest**: 99.14% RÂ² accuracy (best model)
- **320 anomalies detected** across multiple methods
- **Interactive dashboard** with risk maps and visualizations
- **69 engineered features** including lag and seasonal patterns

## ğŸ”§ Components

### 1. Data Collection (`data_collection.py`)
- Loads raw CSV files from DengAI competition
- Merges climate features with dengue case reports
- Creates SQLite database with proper schema
- Provides SQL queries for feature extraction by region/month

### 2. Data Wrangling (`data_wrangling.py`)
- Handles missing values using KNN imputation
- Detects and handles outliers using IQR method
- Standardizes date formats and creates date features
- Validates data consistency

### 3. Feature Engineering (`feature_engineering.py`)
- Creates lag features from previous weeks' cases
- Generates rolling averages and statistical features
- Adds seasonal and cyclical features
- Creates interaction features between climate variables
- Encodes categorical variables

### 4. ML Models (`ml_models.py`)
- **k-Nearest Neighbors**: Distance-based regression with hyperparameter tuning
- **Naive Bayes**: Gaussian NB adapted for regression through binning
- **Random Forest**: Ensemble method with feature importance analysis
- Cross-validation and performance comparison
- Model persistence and loading

### 5. Anomaly Detection (`anomaly_detection.py`)
- Statistical anomaly detection (IQR, Z-score, Modified Z-score)
- Seasonal anomaly detection based on historical patterns
- ML-based anomaly detection using Isolation Forest
- Outbreak pattern detection for sustained increases
- Comprehensive anomaly scoring and visualization

### 6. Dashboard (`dashboard.py`)
- Interactive Streamlit web application
- Time series visualizations with anomaly highlighting
- Model performance comparison and feature importance
- Real-time prediction capabilities

## ğŸ“Š Dashboard Features

### Overview Tab
- Key metrics and summary statistics
- Total cases, anomaly rates, city comparisons

### Time Series Tab
- Interactive time series plots
- Anomaly highlighting
- Seasonal pattern analysis

### Anomalies Tab
- Anomaly detection summary
- Top anomalies table with scores
- Multiple detection method results

### Data Tab
- Dataset overview and raw data viewer
- Data exploration tools

## ğŸ¯ Model Performance

The project trains and compares three models:

1. **Random Forest** (best performer)
   - MAE: 0.9957, RÂ²: 0.9914 (99.14% variance explained)
   - Handles non-linear relationships
   - Provides feature importance

2. **k-Nearest Neighbors**
   - MAE: 4.5610, RÂ²: 0.8901 (89.01% variance explained)
   - Good for local patterns
   - Distance-based similarity

3. **Naive Bayes**
   - MAE: 5.8870, RÂ²: 0.8218 (82.18% variance explained)
   - Fast training and prediction
   - Baseline comparison

## ğŸš¨ Anomaly Detection Results

- **218 statistical anomalies** (IQR and Z-score based)
- **67 seasonal anomalies** (deviation from historical patterns)
- **146 ML-based anomalies** (Isolation Forest)
- **4 outbreak patterns** (sustained case increases)

## ğŸ” Usage Examples

### Running Individual Components

```python
from src.data_collection import DataCollector
from src.ml_models import MLModelTrainer

# Load and process data
collector = DataCollector()
train_features, train_labels, test_features = collector.load_raw_data()
merged_data = collector.merge_training_data(train_features, train_labels)

# Train models
trainer = MLModelTrainer()
models = trainer.train_all_models(merged_data)
performance = trainer.compare_model_performance()
```

### Custom Anomaly Detection

```python
from src.anomaly_detection import AnomalyDetector

detector = AnomalyDetector()
anomaly_data = detector.comprehensive_anomaly_detection(data)
top_anomalies = detector.get_top_anomalies(anomaly_data, top_n=10)
```

## ğŸ“ˆ Results

After running the complete pipeline, you'll get:

- **Database**: SQLite database with structured climate and case data
- **Models**: Trained ML models with 99.14% accuracy
- **Predictions**: Test set predictions for competition submission
- **Dashboard**: Interactive web app for exploration and monitoring
- **Anomaly Reports**: Detected outbreaks and unusual patterns

## ğŸ› ï¸ Customization

### Adding New Features
Extend `feature_engineering.py` to add custom features:

```python
def create_custom_features(self, df):
    # Add your custom feature engineering logic
    df['custom_feature'] = df['temperature'] * df['humidity']
    return df
```

### New Models
Add models to `ml_models.py`:

```python
def train_custom_model(self, X_train, y_train):
    from sklearn.svm import SVR
    model = SVR()
    model.fit(X_train, y_train)
    return model
```

## ğŸ™ Acknowledgments

- DengAI competition dataset from DrivenData
- Climate data from NOAA and other meteorological sources
- Open source libraries: scikit-learn, pandas, streamlit, plotly

## ğŸ“„ License

This project is open source and available under the MIT License.

---

**Built with â¤ï¸ for public health and disease prevention**