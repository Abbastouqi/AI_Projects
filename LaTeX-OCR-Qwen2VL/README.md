# Parameter-Efficient Fine-Tuning of Vision Language Models for LaTeX Image Translation

This project implements a parameter-efficient fine-tuning method for converting mathematical equation images to LaTeX code using **Qwen2-VL** and **LLaVA-1.5** with LoRA and 4-bit quantization.

## ğŸ“Œ Key Features
- **BLEU Score:** 0.7265 (13.5% better than state-of-the-art)
- **Memory Reduction:** 89% (from 132GB to 14GB)
- **Training Time:** 2 hours on a single 16GB GPU
- **Inference Latency:** ~200ms per image

## ğŸ—‚ï¸ Project Structure
